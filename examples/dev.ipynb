{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe10e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e82a56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94019ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c538359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.services.llm import AnthropicBatchProvider, build_extraction_batch_request\n",
    "from src.knowledge_graph.schemas import ExtractionResult, Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7fd77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2026-01-12 13:27:26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mbatch_provider_initialized    \u001b[0m \u001b[36mapi_key\u001b[0m=\u001b[35m...ZQAA\u001b[0m \u001b[36mjobs_dir\u001b[0m=\u001b[35m../data/batch_jobs\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.services.llm import AnthropicBatchProvider, build_extraction_batch_request\n",
    "from src.knowledge_graph.schemas import ExtractionResult, Ontology\n",
    "\n",
    "# ============================================================================\n",
    "# Extraction prompt template (from src/knowledge_graph/extract_entities_batch.py)\n",
    "# ============================================================================\n",
    "EXTRACTION_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert knowledge graph extractor for the \"{series_name}\" series.\n",
    "Your goal is to extract a comprehensive list of entities and relationships from the provided text chunk.\n",
    "\n",
    "STRICT ADHERENCE & ADAPTIVE EVOLOUTION:\n",
    "1. You must primarily use the provided Ontology Schema to categorize entities and relationships.\n",
    "2. IF you encounter a significant entity or relationship that strongly clearly does NOT fit existing definitions:\n",
    "   - DO NOT force it into an incorrect category.\n",
    "   - DO NOT ignore it if it is important.\n",
    "   - PROPOSE a schema update in the `schema_proposals` field (e.g., \"new_entity_type\", \"new_relationship_type\").\n",
    "3. Use the Canonical Renaming Rules to normalize entity names.\n",
    "\n",
    "INPUT CONTEXT:\n",
    "This text is from: {book_names}\n",
    "Section ID: {section_id}\n",
    "\n",
    "TASK:\n",
    "1. Identify all significant entities (Characters, Locations, Organizations, Artifacts, Events, etc.).\n",
    "2. Extract detailed attributes for each entity.\n",
    "3. Identify all relationships between these entities.\n",
    "4. Extract evidence (quotes) for relationships.\n",
    "5. Assign a CONFIDENCE score (0.0-1.0) to each extraction.\n",
    "6. Identify gaps in the schema and propose updates in `schema_proposals`.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return a JSON object strictly matching the `ExtractionResult` Pydantic model.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# Initialize provider\n",
    "# ============================================================================\n",
    "provider = AnthropicBatchProvider(\n",
    "    api_key=anthropic_api_key,  \n",
    "    jobs_dir=\"../data/batch_jobs\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Load schema and build extraction prompt for one section\n",
    "# ============================================================================\n",
    "# Load ontology schema for the series\n",
    "with open(\"../data/schemas/harry_potter_schema.json\", \"r\") as f:\n",
    "    schema_data = json.load(f)\n",
    "ontology = Ontology(**schema_data)\n",
    "schema_context = f\"ONTOLOGY:\\n{ontology.model_dump_json(indent=2)}\"\n",
    "\n",
    "# Load one section file\n",
    "section_file = Path(\"../data/processed_books_claude_200k/harry_potter_section_01.txt\")\n",
    "text_content = section_file.read_text()\n",
    "\n",
    "# Load metadata\n",
    "with open(\"../data/processed_books_claude_200k/harry_potter_section_01.meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "book_names = \", \".join(meta.get(\"books\", []))\n",
    "section_id = str(meta.get(\"section\", \"1\"))\n",
    "\n",
    "# Build full prompt\n",
    "extraction_prompt = EXTRACTION_PROMPT_TEMPLATE.format(\n",
    "    series_name=\"Harry Potter\",\n",
    "    book_names=book_names,\n",
    "    section_id=section_id,\n",
    ")\n",
    "full_prompt = f\"{extraction_prompt}\\n\\n{schema_context}\\n\\nTEXT CONTENT:\\n{text_content}\"\n",
    "\n",
    "# Create batch request using ExtractionResult schema\n",
    "requests = [\n",
    "    build_extraction_batch_request(\n",
    "        custom_id=\"harry_potter_section_01\",\n",
    "        prompt=full_prompt,\n",
    "        model=\"claude-opus-4-5-20251101\",\n",
    "        schema=ExtractionResult,  # Pydantic model from src/knowledge_graph/schemas.py\n",
    "        max_tokens=64000,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Submit batch\n",
    "# ============================================================================\n",
    "job = await provider.create_batch(\n",
    "    requests=requests,\n",
    "    output_dir=\"../data/extracted_graph_batch\",\n",
    "    model=\"claude-opus-4-5-20251101\",\n",
    "    series_name=\"Harry Potter\"\n",
    ")\n",
    "\n",
    "print(f\"Batch ID: {job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ee4923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2026-01-12 13:27:32\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mjob_saved                     \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mpath\u001b[0m=\u001b[35m../data/batch_jobs/msgbatch_01SM3TT5kGqVeajXysiPkj49.json\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m\n",
      "\u001b[2m2026-01-12 13:27:32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mbatch_status_retrieved        \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mendpoint\u001b[0m=\u001b[35mget_batch_status\u001b[0m \u001b[36merrored\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mprocessing\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mended\u001b[0m \u001b[36msucceeded\u001b[0m=\u001b[35m1\u001b[0m\n",
      "Status: ended\n",
      "Succeeded: 1\n",
      "Processing: 0\n"
     ]
    }
   ],
   "source": [
    "status = await provider.get_batch_status(\"msgbatch_01SM3TT5kGqVeajXysiPkj49\")\n",
    "print(f\"Status: {status.processing_status}\")\n",
    "print(f\"Succeeded: {status.request_counts.succeeded}\")\n",
    "print(f\"Processing: {status.request_counts.processing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c62a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2026-01-12 13:27:34\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mjob_saved                     \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mpath\u001b[0m=\u001b[35m../data/batch_jobs/msgbatch_01SM3TT5kGqVeajXysiPkj49.json\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m\n",
      "\u001b[2m2026-01-12 13:27:34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mbatch_status_retrieved        \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mendpoint\u001b[0m=\u001b[35mget_batch_status\u001b[0m \u001b[36merrored\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mprocessing\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m \u001b[36mstatus\u001b[0m=\u001b[35mended\u001b[0m \u001b[36msucceeded\u001b[0m=\u001b[35m1\u001b[0m\n",
      "\u001b[2m2026-01-12 13:27:34\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mretrieving_batch_results      \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mendpoint\u001b[0m=\u001b[35mretrieve_results\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m\n",
      "\u001b[2m2026-01-12 13:27:35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mbatch_results_retrieved       \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mendpoint\u001b[0m=\u001b[35mretrieve_results\u001b[0m \u001b[36merrored\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m \u001b[36msucceeded\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mtotal_results\u001b[0m=\u001b[35m1\u001b[0m\n",
      "\u001b[2m2026-01-12 13:27:35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mresult_processed              \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mcustom_id\u001b[0m=\u001b[35mharry_potter_section_01\u001b[0m \u001b[36mendpoint\u001b[0m=\u001b[35mprocess_results_to_files\u001b[0m \u001b[36moutput_file\u001b[0m=\u001b[35m../data/extracted_graph_batch/harry_potter_section_01_extracted.json\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m \u001b[36mschema_name\u001b[0m=\u001b[35mExtractionResult\u001b[0m\n",
      "\u001b[2m2026-01-12 13:27:35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mbatch_processing_complete     \u001b[0m \u001b[36mbatch_id\u001b[0m=\u001b[35mmsgbatch_01SM3TT5kGqVeajXysiPkj49\u001b[0m \u001b[36mendpoint\u001b[0m=\u001b[35mprocess_results_to_files\u001b[0m \u001b[36mfailed\u001b[0m=\u001b[35m0\u001b[0m \u001b[36mfiles_written\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mprocessed\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mAnthropicBatchProvider\u001b[0m \u001b[36mschema_name\u001b[0m=\u001b[35mExtractionResult\u001b[0m \u001b[36mtotal_tokens\u001b[0m=\u001b[35m151882\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = await provider.process_results_to_files(\n",
    "    batch_id=\"msgbatch_01SM3TT5kGqVeajXysiPkj49\",\n",
    "    schema=ExtractionResult\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb07fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'processed': 1,\n",
       " 'failed': 0,\n",
       " 'usage': UsageMetrics(input_tokens=123342, output_tokens=28540, total_tokens=151882, cached_tokens=0, reasoning_tokens=0, input_cost_usd=None, output_cost_usd=None, total_cost_usd=None, provider='anthropic', model='claude-opus-4-5-20251101', timestamp=1768204655.095932, api_key_last4='...ZQAA'),\n",
       " 'files_written': ['../data/extracted_graph_batch/harry_potter_section_01_extracted.json']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
